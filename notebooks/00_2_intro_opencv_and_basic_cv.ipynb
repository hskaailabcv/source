{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook contains the first two exercises about basic principles in computer vision. Solve them by filling in the ToDo's with your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed imports and configuration for matplotlib\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.exposure import rescale_intensity\n",
    "import numpy as np\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some utility functions to draw the images using matplotlib\n",
    "def showBGR(imgBGR):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.imshow(cv2.cvtColor(imgBGR, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "def showGray(image):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.imshow(image,cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Convolution without OpenCV\n",
    "\n",
    "The convolution of an image and a convolution mask (kernel) can be used as linear filter for a myriad of applications in computer vision. Depending on the structure of a kernel, we can use it to blur or sharpen the image, extract edges and many more. The convolution can be described using the following equation:\n",
    "\n",
    "$ F(x,y) =  f(x,y) \\otimes  g(x,y) = \\sum_{s=-a}^{a} \\sum_{t=-b}^{b} f(s,t)g(x-s, y-t) $\n",
    "\n",
    "In this exercise, you will implement your the convolution in the cell below and apply different kernels to filter your input image. Compare your results with the one computed by the OpenCV implementation two cells below.\n",
    "\n",
    "The following steps serve as a support in case you are not sure where to start:\n",
    "\n",
    "   1. create a padded version of your input image where the border region reflects the first/last value of the vector along the axis (Thus, a column abc with a padding of two will become aaabccc)\n",
    "   2. compute the convolution between the kernel and the image. Use the center point of the kernel as the anchor point.\n",
    "   3. rescale the intensity, so that you will end up with an uint8 image. You can use the rescale_intensity function of skimage.exposure to accomplish this task.\n",
    "   4. return the uint8 version of your convolved image.\n",
    "    \n",
    "During the whole process, be aware that numpy won't prevent you from any overflow encountered during the operation!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve2d(image, kernel):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputImage = cv2.imread(\"resources/got.jpg\", cv2.IMREAD_COLOR)\n",
    "showBGR(inputImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell calls your implementation of the convolution and compares the result to the one computed by `cv2.filter2D`. Feel free to change the kernel and see how it affect the image of the  Iron Throne. Use the following page as a reference for different kernel types: http://setosa.io/ev/image-kernels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grayImage = cv2.cvtColor(inputImage, cv2.COLOR_BGR2GRAY)\n",
    "k = np.array([1, 0, -1, 2, 0, -2, 1, 0, -1]).reshape(3,3)\n",
    "\n",
    "ownConv = convolve2d(grayImage, k)\n",
    "ocvConv = cv2.filter2D(grayImage, -1, k)\n",
    "\n",
    "print(k)\n",
    "assert(np.allclose(ownConv, ocvConv, rtol=1e-05))\n",
    "showGray(ownConv)\n",
    "showGray(ocvConv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Classification of Tetris pieces with OpenCV\n",
    "\n",
    "You do not necessarily need deep learning for any classification task. Sometimes, the basics of computer vision are just enough to distinguish different objects. This holds true for the following task, which requires you to classify the different tetris pieces based on their shape. Use contour properties to accomplish this task. Your solution should contain at least the following steps:\n",
    "   1. create a smoothed grayscale image from the input image\n",
    "   2. threshold the grayscale image. Choose a good threshold to seperate the pieces from the white background\n",
    "   3. extract the contours from the image using OpenCV\n",
    "   4. Compute different contour properties, e.g. area of the object, aspect ratio, extent, convecHull/hullArea, solidity, ... Use the following as a reference: https://docs.opencv.org/4.0.1/d3/d05/tutorial_py_table_of_contents_contours.html\n",
    "   5. try to distinguish the different Block types (which are **Square**, **Rectangle**, **L-Piece**, **Z-Piece** and **T-Piece**)\n",
    "   6. Print the computed contour properties and the resulting classification result out\n",
    "   7. Draw the contour and the classification on a copy of the input display your results. \n",
    "   \n",
    "Use the wohle OpenCV Documentation as a reference. It contains a nicely structured Python tutorial which can be found here: https://docs.opencv.org/4.0.1/d6/d00/tutorial_py_root.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and display source image \n",
    "tetris = cv2.imread(\"resources/tetris.png\", cv2.IMREAD_COLOR)\n",
    "showBGR(tetris)\n",
    "\n",
    "\n",
    "# create smoothed grayscale image\n",
    "grayImage =  # ToDo\n",
    "\n",
    "# remove noise in the thresholded image\n",
    "kernel = np.ones((5,5))\n",
    "thresh = cv2.dilate(thresh,kernel,iterations = 1)\n",
    "\n",
    "\n",
    "# find external contours in the thresholded image and allocate memory\n",
    "# for the convex hull image\n",
    "contours =  # ToDo\n",
    "hullImage = np.zeros(grayImage.shape[:2], dtype=\"uint8\")\n",
    "\n",
    "drawImage = tetris.copy()\n",
    "# loop over the contours\n",
    "for (i, c) in enumerate(contours):\n",
    "    # Todo: compute properties for each contour\n",
    "    \n",
    "    \n",
    "    cv2.drawContours(drawImage, [c], -1, (0, 0, 0), 3)\n",
    "    shape = \"\"\n",
    "    \n",
    "    #ToDo: Use your computed contours to distinguish between the different block types.\n",
    "    if :\n",
    "        shape = \"SQUARE\"\n",
    "    elif:\n",
    "        shape = \"RECTANGLE\"\n",
    "    elif :\n",
    "        shape = \"T-PIECE\"\n",
    "    elif :\n",
    "        shape = \"L-PIECE\"\n",
    "    elif :\n",
    "        shape = \"Z-PIECE\"\n",
    "        \n",
    "    # draw the shape name on the image\n",
    "    cv2.putText(drawImage, shape, (x, y - 5), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.7,\n",
    "        (0, 0, 0), 1)\n",
    " \n",
    "    # show the contour properties\n",
    "    # ToDo: print all your properties and your classification result\n",
    "    print()\n",
    "    \n",
    "# show the output image\n",
    "showBGR(drawImage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
