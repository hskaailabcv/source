{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 CNN-Test Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_dataset_folder_path = \"./cifar-10-batches-py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cfar10_batch(cifar10_dataset_folder_path, batch_id):\n",
    "    with open(cifar10_dataset_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "        # note the encoding type is 'latin1'\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    labels = batch['labels']\n",
    "        \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_stats(cifar10_dataset_folder_path, batch_id, sample_id):\n",
    "    features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_id)\n",
    "    \n",
    "    if not (0 <= sample_id < len(features)):\n",
    "        print('{} samples in batch {}.  {} is out of range.'.format(len(features), batch_id, sample_id))\n",
    "        return None\n",
    "\n",
    "    print('\\nStats of batch #{}:'.format(batch_id))\n",
    "    print('# of Samples: {}\\n'.format(len(features)))\n",
    "    \n",
    "    label_names = load_label_names()\n",
    "    label_counts = dict(zip(*np.unique(labels, return_counts=True)))\n",
    "    for key, value in label_counts.items():\n",
    "        print('Label Counts of [{}]({}) : {}'.format(key, label_names[key].upper(), value))\n",
    "    \n",
    "    sample_image = features[sample_id]\n",
    "    sample_label = labels[sample_id]\n",
    "    \n",
    "    print('\\nExample of Image {}:'.format(sample_id))\n",
    "    print('Image - Min Value: {} Max Value: {}'.format(sample_image.min(), sample_image.max()))\n",
    "    print('Image - Shape: {}'.format(sample_image.shape))\n",
    "    print('Label - Label Id: {} Name: {}'.format(sample_label, label_names[sample_label]))\n",
    "    \n",
    "    plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch #3:\n",
      "# of Samples: 10000\n",
      "\n",
      "Label Counts of [0](AIRPLANE) : 994\n",
      "Label Counts of [1](AUTOMOBILE) : 1042\n",
      "Label Counts of [2](BIRD) : 965\n",
      "Label Counts of [3](CAT) : 997\n",
      "Label Counts of [4](DEER) : 990\n",
      "Label Counts of [5](DOG) : 1029\n",
      "Label Counts of [6](FROG) : 978\n",
      "Label Counts of [7](HORSE) : 1015\n",
      "Label Counts of [8](SHIP) : 961\n",
      "Label Counts of [9](TRUCK) : 1029\n",
      "\n",
      "Example of Image 7000:\n",
      "Image - Min Value: 24 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 0 Name: airplane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_id = 3\n",
    "sample_id = 7000\n",
    "display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: input image data in numpy array [32, 32, 3]\n",
    "        return\n",
    "            - normalized x \n",
    "    \"\"\"\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    x = (x-min_val) / (max_val-min_val)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: a list of labels\n",
    "        return\n",
    "            - one hot encoding matrix (number of labels, number of class)\n",
    "    \"\"\"\n",
    "    encoded = np.zeros((len(x), 10))\n",
    "    \n",
    "    for idx, val in enumerate(x):\n",
    "        encoded[idx][val] = 1\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_and_save(normalize, one_hot_encode, features, labels, filename):\n",
    "    features = normalize(features)\n",
    "    labels = one_hot_encode(labels)\n",
    "\n",
    "    pickle.dump((features, labels), open(filename, 'wb'))\n",
    "\n",
    "\n",
    "def preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode):\n",
    "    n_batches = 5\n",
    "    valid_features = []\n",
    "    valid_labels = []\n",
    "\n",
    "    for batch_i in range(1, n_batches + 1):\n",
    "        features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_i)\n",
    "        \n",
    "        # find index to be the point as validation data in the whole dataset of the batch (10%)\n",
    "        index_of_validation = int(len(features) * 0.1)\n",
    "\n",
    "        # preprocess the 90% of the whole dataset of the batch\n",
    "        # - normalize the features\n",
    "        # - one_hot_encode the lables\n",
    "        # - save in a new file named, \"preprocess_batch_\" + batch_number\n",
    "        # - each file for each batch\n",
    "        _preprocess_and_save(normalize, one_hot_encode,\n",
    "                             features[:-index_of_validation], labels[:-index_of_validation], \n",
    "                             'preprocess_batch_' + str(batch_i) + '.p')\n",
    "\n",
    "        # unlike the training dataset, validation dataset will be added through all batch dataset\n",
    "        # - take 10% of the whold dataset of the batch\n",
    "        # - add them into a list of\n",
    "        #   - valid_features\n",
    "        #   - valid_labels\n",
    "        valid_features.extend(features[-index_of_validation:])\n",
    "        valid_labels.extend(labels[-index_of_validation:])\n",
    "\n",
    "    # preprocess the all stacked validation dataset\n",
    "    _preprocess_and_save(normalize, one_hot_encode,\n",
    "                         np.array(valid_features), np.array(valid_labels),\n",
    "                         'preprocess_validation.p')\n",
    "\n",
    "    # load the test dataset\n",
    "    with open(cifar10_dataset_folder_path + '/test_batch', mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    # preprocess the testing data\n",
    "    test_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    test_labels = batch['labels']\n",
    "\n",
    "    # Preprocess and Save all testing data\n",
    "    _preprocess_and_save(normalize, one_hot_encode,\n",
    "                         np.array(test_features), np.array(test_labels),\n",
    "                         'preprocess_training.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3), name='input_x')\n",
    "y =  tf.placeholder(tf.float32, shape=(None, 10), name='output_y')\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    conv1_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 3, 64], mean=0, stddev=0.08))\n",
    "    conv2_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 128], mean=0, stddev=0.08))\n",
    "    conv3_filter = tf.Variable(tf.truncated_normal(shape=[5, 5, 128, 256], mean=0, stddev=0.08))\n",
    "    conv4_filter = tf.Variable(tf.truncated_normal(shape=[5, 5, 256, 512], mean=0, stddev=0.08))\n",
    "\n",
    "    # 1, 2\n",
    "    conv1 = tf.nn.conv2d(x, conv1_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    conv1_pool = tf.nn.max_pool(conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    conv1_bn = tf.layers.batch_normalization(conv1_pool)\n",
    "\n",
    "    # 3, 4\n",
    "    conv2 = tf.nn.conv2d(conv1_bn, conv2_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    conv2_pool = tf.nn.max_pool(conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')    \n",
    "    conv2_bn = tf.layers.batch_normalization(conv2_pool)\n",
    "  \n",
    "    # 5, 6\n",
    "    conv3 = tf.nn.conv2d(conv2_bn, conv3_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "    conv3_pool = tf.nn.max_pool(conv3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')  \n",
    "    conv3_bn = tf.layers.batch_normalization(conv3_pool)\n",
    "    \n",
    "    # 7, 8\n",
    "    conv4 = tf.nn.conv2d(conv3_bn, conv4_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv4 = tf.nn.relu(conv4)\n",
    "    conv4_pool = tf.nn.max_pool(conv4, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    conv4_bn = tf.layers.batch_normalization(conv4_pool)\n",
    "    \n",
    "    # 9\n",
    "    flat = tf.contrib.layers.flatten(conv4_bn)  \n",
    "\n",
    "    # 10\n",
    "    full1 = tf.contrib.layers.fully_connected(inputs=flat, num_outputs=128, activation_fn=tf.nn.relu)\n",
    "    full1 = tf.nn.dropout(full1, keep_prob)\n",
    "    full1 = tf.layers.batch_normalization(full1)\n",
    "    \n",
    "    # 11\n",
    "    full2 = tf.contrib.layers.fully_connected(inputs=full1, num_outputs=256, activation_fn=tf.nn.relu)\n",
    "    full2 = tf.nn.dropout(full2, keep_prob)\n",
    "    full2 = tf.layers.batch_normalization(full2)\n",
    "    \n",
    "    # 12\n",
    "    full3 = tf.contrib.layers.fully_connected(inputs=full2, num_outputs=512, activation_fn=tf.nn.relu)\n",
    "    full3 = tf.nn.dropout(full3, keep_prob)\n",
    "    full3 = tf.layers.batch_normalization(full3)    \n",
    "    \n",
    "    # 13\n",
    "    full4 = tf.contrib.layers.fully_connected(inputs=full3, num_outputs=1024, activation_fn=tf.nn.relu)\n",
    "    full4 = tf.nn.dropout(full4, keep_prob)\n",
    "    full4 = tf.layers.batch_normalization(full4)        \n",
    "    \n",
    "    # 14\n",
    "    out = tf.contrib.layers.fully_connected(inputs=full3, num_outputs=10, activation_fn=None)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "keep_probability = 0.7\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-19-aa21eb445378>:11: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-19-aa21eb445378>:36: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-21-bc29ffa8bb57>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logits = conv_net(x, keep_prob)\n",
    "model = tf.identity(logits, name='logits') # Name logits Tensor, so that can be loaded from disk after training\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    session.run(optimizer, \n",
    "                feed_dict={\n",
    "                    x: feature_batch,\n",
    "                    y: label_batch,\n",
    "                    keep_prob: keep_probability\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    loss = sess.run(cost, \n",
    "                    feed_dict={\n",
    "                        x: feature_batch,\n",
    "                        y: label_batch,\n",
    "                        keep_prob: 1.\n",
    "                    })\n",
    "    valid_acc = sess.run(accuracy, \n",
    "                         feed_dict={\n",
    "                             x: valid_features,\n",
    "                             y: valid_labels,\n",
    "                             keep_prob: 1.\n",
    "                         })\n",
    "    \n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]\n",
    "\n",
    "def load_preprocess_training_batch(batch_id, batch_size):\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    filename = 'preprocess_batch_' + str(batch_id) + '.p'\n",
    "    features, labels = pickle.load(open(filename, mode='rb'))\n",
    "\n",
    "    # Return the training data in batches of size <batch_size> or less\n",
    "    return batch_features_labels(features, labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor of shape [3,3,64,128] and type float\n\t [[node Variable_1/Adam_1/Initializer/zeros (defined at <ipython-input-21-bc29ffa8bb57>:6) ]]\n\nCaused by op 'Variable_1/Adam_1/Initializer/zeros', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-bc29ffa8bb57>\", line 6, in <module>\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py\", line 413, in minimize\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py\", line 595, in apply_gradients\n    self._create_slots(var_list)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/adam.py\", line 136, in _create_slots\n    self._zeros_slot(v, \"v\", self._name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py\", line 1153, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/slot_creator.py\", line 183, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/slot_creator.py\", line 157, in create_slot_with_initializer\n    dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1479, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1220, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 547, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 499, in _true_getter\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 911, in _get_single_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 1503, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 883, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py\", line 110, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 1817, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3367, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [3,3,64,128] and type float\n\t [[node Variable_1/Adam_1/Initializer/zeros (defined at <ipython-input-21-bc29ffa8bb57>:6) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [3,3,64,128] and type float\n\t [[{{node Variable_1/Adam_1/Initializer/zeros}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-783b0a1d950f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Initializing the variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Training cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [3,3,64,128] and type float\n\t [[node Variable_1/Adam_1/Initializer/zeros (defined at <ipython-input-21-bc29ffa8bb57>:6) ]]\n\nCaused by op 'Variable_1/Adam_1/Initializer/zeros', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-bc29ffa8bb57>\", line 6, in <module>\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py\", line 413, in minimize\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py\", line 595, in apply_gradients\n    self._create_slots(var_list)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/adam.py\", line 136, in _create_slots\n    self._zeros_slot(v, \"v\", self._name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py\", line 1153, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/slot_creator.py\", line 183, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/slot_creator.py\", line 157, in create_slot_with_initializer\n    dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1479, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1220, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 547, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 499, in _true_getter\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 911, in _get_single_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 1503, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 883, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py\", line 110, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 1817, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3367, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [3,3,64,128] and type float\n\t [[node Variable_1/Adam_1/Initializer/zeros (defined at <ipython-input-21-bc29ffa8bb57>:6) ]]\n"
     ]
    }
   ],
   "source": [
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "                \n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
