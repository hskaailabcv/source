{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Object Classification\n",
    "\n",
    "The CIFAR-10 dataset contains 60k 32x32 pixel color images from 10 different classes.\n",
    "\n",
    "The classes are:\n",
    "- airplane \n",
    "- automobile \n",
    "- bird \n",
    "- cat \n",
    "- deer \n",
    "- dog \n",
    "- frog \n",
    "- horse \n",
    "- ship \n",
    "- truck\n",
    "\n",
    "Tasks:\n",
    "\n",
    "- implement the TODOs\n",
    "- train a MLP to achieve >50% test accuracy\n",
    "- train a CNN to achieve >80% test accuracy\n",
    "\n",
    "Help:\n",
    "- use the Keras API Documentation [https://www.keras.io/)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T09:16:15.832547Z",
     "start_time": "2019-10-17T09:16:00.665123Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "# download CIFAR-10 if needed\n",
    "if [ ! -d cifar-10-batches-py ]; then\n",
    "    wget -c -q https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "    tar xzf cifar-10-python.tar.gz\n",
    "    rm cifar-10-python.tar.gz\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T19:03:49.424862Z",
     "start_time": "2019-10-17T19:03:49.420290Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T19:07:45.207184Z",
     "start_time": "2019-10-17T19:07:45.202930Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to unpickle data files\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        return pickle.load(fo, encoding='bytes')\n",
    "\n",
    "# function to store  data in pickle file\n",
    "def store(obj, filename):\n",
    "    pickle.dump(obj, open('cifar-10-batches-py/' + filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T19:07:45.705602Z",
     "start_time": "2019-10-17T19:07:45.693257Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: decode pickle data as images\n",
    "# see https://www.cs.toronto.edu/~kriz/cifar.html for the storage format\n",
    "def decode_as_image(img_flat):\n",
    "    img_R =\n",
    "    img_G =\n",
    "    img_B =\n",
    "    return np.dstack((img_R, img_G, img_B)).reshape(32, 32, 3)\n",
    "\n",
    "# NOTE: alternatively use reshape & np.rollaxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:28:29.770521Z",
     "start_time": "2019-10-17T18:28:29.057316Z"
    }
   },
   "outputs": [],
   "source": [
    "# load train data and save to disk for later usage\n",
    "# note: you might need to give Docker more memory\n",
    "# alternatively, execute separately\n",
    "x_train = []\n",
    "for i in range(1, 6):\n",
    "    x_train_b = unpickle('cifar-10-batches-py/data_batch_' + str(i)).get(bytes('data', 'ascii'))\n",
    "    for img in x_train_b:\n",
    "        img = decode_as_image(img)\n",
    "        x_train.append(img)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "assert x_train.shape == (50000, 32, 32, 3)\n",
    "        \n",
    "# save to disk\n",
    "store(x_train, 'x_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:28:48.352156Z",
     "start_time": "2019-10-17T18:28:48.196333Z"
    }
   },
   "outputs": [],
   "source": [
    "# load test data and save to disk for later usage\n",
    "x_test = []\n",
    "x_test_b = unpickle('cifar-10-batches-py/test_batch').get(bytes('data', 'ascii'))\n",
    "for img in x_test_b:\n",
    "    img = decode_as_image(img)\n",
    "    x_test.append(img)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "assert x_test.shape == (10000, 32, 32, 3)\n",
    "    \n",
    "# save to disk\n",
    "store(x_test, 'x_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T19:06:35.736132Z",
     "start_time": "2019-10-17T19:06:35.532987Z"
    }
   },
   "outputs": [],
   "source": [
    "# load train and test labels and save to disk\n",
    "y_train = np.concatenate([\n",
    "    unpickle('cifar-10-batches-py/data_batch_' + str(i)).get(bytes('labels', 'ascii'))\n",
    "    for i in range(1, 6)\n",
    "])\n",
    "assert y_train.shape == (50000,)\n",
    "store(y_train, 'y_train')\n",
    "\n",
    "y_test = np.array(unpickle('cifar-10-batches-py/test_batch').get(bytes('labels', 'ascii')))\n",
    "assert y_test.shape == (10000,)\n",
    "store(y_test, 'y_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T19:07:49.516623Z",
     "start_time": "2019-10-17T19:07:49.335325Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = unpickle(\"cifar-10-batches-py/x_train\")\n",
    "x_test = unpickle(\"cifar-10-batches-py/x_test\")\n",
    "y_train = unpickle(\"cifar-10-batches-py/y_train\")\n",
    "y_test = unpickle(\"cifar-10-batches-py/y_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T19:07:50.511401Z",
     "start_time": "2019-10-17T19:07:50.095818Z"
    }
   },
   "outputs": [],
   "source": [
    "# show 5 random training samples\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_mapping = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "indices = np.arange(x_train.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "plt.figure(figsize=(18,3))\n",
    "for i, idx in enumerate(indices[:5]):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.title(\"Class: {}\".format(label_mapping[int(y_train[idx])]))\n",
    "    plt.imshow(x_train[idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset for training and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:29:38.301104Z",
     "start_time": "2019-10-17T18:29:38.022966Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: normalize data and cast to float32\n",
    "x_train, x_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:29:39.635086Z",
     "start_time": "2019-10-17T18:29:39.630573Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: figure out number of classes (preferably from the data)\n",
    "n_classes = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:29:42.587252Z",
     "start_time": "2019-10-17T18:29:41.218016Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, n_classes)\n",
    "y_test = to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:14:04.489770Z",
     "start_time": "2019-10-17T18:14:04.486643Z"
    }
   },
   "source": [
    "# The Multi Layer Perceptron\n",
    "\n",
    "## 1. Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:49:12.710623Z",
     "start_time": "2019-10-17T18:49:12.648370Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: define the mlp model\n",
    "from keras.layers import Flatten, Dense, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "mlp = Sequential([\n",
    "    Flatten(input_shape=(32, 32, 3)),\n",
    "    ...,\n",
    "    FILL,\n",
    "    ME,\n",
    "    IN,\n",
    "    ...,\n",
    "    Dense(n_classes),\n",
    "    Activation('softmax')\n",
    "])\n",
    "\n",
    "\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:14:15.075879Z",
     "start_time": "2019-10-17T18:14:15.070105Z"
    }
   },
   "source": [
    "## 2. Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:46:29.270731Z",
     "start_time": "2019-10-17T18:46:29.224105Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: fill in learning rate, change optimize, etc\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "mlp.compile(loss='categorical_crossentropy',\n",
    "            optimizer=Adam(learning_rate=... FILL ME IN ...),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train (fit) the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:45:04.470248Z",
     "start_time": "2019-10-17T18:43:03.839652Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: decide training parameters, insert a learning rate schedule - GO WILD!\n",
    "batch_size = \n",
    "epochs = \n",
    "\n",
    "mlp.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "        validation_data=(x_test, y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the model\n",
    "\n",
    "Compute this metric:\n",
    "\n",
    "$$\\text{accuracy} = \\frac{N_{\\text{correct}}}{N_{\\text{total}}}$$\n",
    "\n",
    "Extra credit (for life, not this course): See [Wikipedia: Confusion Matrix](https://en.wikipedia.org/wiki/Confusion_matrix) for why accuracy is not always a good choice when evaluating models and what metric(s) to use instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:37:37.484084Z",
     "start_time": "2019-10-17T18:37:37.479527Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: compute accuracy\n",
    "def get_accuracy(predictions, ground_truth):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:41:59.420075Z",
     "start_time": "2019-10-17T18:41:58.730117Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp_scores = mlp.evaluate(x_test, y_test, verbose=0)\n",
    "predictions = mlp.predict(x_test)\n",
    "\n",
    "print(\"MLP Accuracy:\", mlp_scores[1])\n",
    "print(\"My MLP Accuracy:\", get_accuracy(predictions, y_test))\n",
    "assert np.isclose(mlp_scores[1], get_accuracy(predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:50:41.557938Z",
     "start_time": "2019-10-17T18:50:41.480576Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: define the cnn model\n",
    "from keras.layers import MaxPooling2D, Flatten, Dense, Conv2D, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "cnn = Sequential([\n",
    "    ... FILL ME IN ...\n",
    "])\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:53:18.117287Z",
     "start_time": "2019-10-17T18:52:00.278Z"
    }
   },
   "source": [
    "## 2. Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:50:53.147288Z",
     "start_time": "2019-10-17T18:50:53.111279Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: fill in learning rate, change optimize, etc\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "cnn.compile(loss='categorical_crossentropy',\n",
    "            optimizer=RMSprop(learning_rate=... FILL ME IN ...),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:53:18.108561Z",
     "start_time": "2019-10-17T18:50:53.567954Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: decide training parameters, insert a learning rate schedule - GO WILD!\n",
    "batch_size =\n",
    "epochs =\n",
    "\n",
    "cnn.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "        validation_data=(x_test, y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:53:18.123346Z",
     "start_time": "2019-10-17T18:52:24.364Z"
    }
   },
   "source": [
    "## 4. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T18:53:43.340229Z",
     "start_time": "2019-10-17T18:53:40.017736Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_scores = cnn.evaluate(x_test, y_test, verbose=0)\n",
    "predictions = cnn.predict(x_test)\n",
    "\n",
    "print(\"CNN Accuracy:\", cnn_scores[1])\n",
    "print(\"My CNN Accuracy:\", get_accuracy(predictions, y_test))\n",
    "assert np.isclose(cnn_scores[1], get_accuracy(predictions, y_test))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
