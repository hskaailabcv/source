{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Object Classification\n",
    "\n",
    "The CIFAR-10 dataset contains 60k 32x32 pixel color images from 10 different classes.\n",
    "\n",
    "The classes are:\n",
    "- airplane \n",
    "- automobile \n",
    "- bird \n",
    "- cat \n",
    "- deer \n",
    "- dog \n",
    "- frog \n",
    "- horse \n",
    "- ship \n",
    "- truck\n",
    "\n",
    "Tasks:\n",
    "\n",
    "- implement the TODOs\n",
    "- use the keras [Keras Functional API](https://keras.io/getting-started/functional-api-guide/) to define your models!\n",
    "- train a MLP to achieve >40% test accuracy\n",
    "- add TensorBoard summaries (and display them in notebook)\n",
    "- train a CNN to achieve >80% test accuracy\n",
    "\n",
    "Help:\n",
    "- use the TensorFlow API Documentation [https://www.tensorflow.org/api_docs/](https://www.tensorflow.org/api_docs/)\n",
    "- and the keras API Documentation [https://keras.io/]\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# download CIFAR-10\n",
    "wget -q https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "# unpack\n",
    "tar xzf cifar-10-python.tar.gz\n",
    "# remove tar.gz\n",
    "rm cifar-10-python.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "%load_ext tensorboard\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to unpickle data files\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        obj = pickle.load(fo, encoding='bytes')\n",
    "    return obj\n",
    "\n",
    "# function to store  data in pickle file\n",
    "def store(obj, filename):\n",
    "    pickle.dump(obj, open('cifar-10-batches-py/' + filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: decode pickle data as images\n",
    "# see https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "def decode_as_image(img_flat):\n",
    "    img_R = \n",
    "    img_G = \n",
    "    img_B = \n",
    "    return np.dstack((img_R, img_G, img_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data and save to disk for later usage\n",
    "# note: you might need to give Docker more memory\n",
    "# alternatively, execute separately\n",
    "x_train = []\n",
    "for i in range(1, 6):\n",
    "    x_train_b = unpickle('cifar-10-batches-py/data_batch_' + str(i)).get(bytes('data', 'ascii'))\n",
    "    for img in x_train_b:\n",
    "        img = decode_as_image(x_train_b)\n",
    "        x_train.append(img)\n",
    "\n",
    "# reshape the data\n",
    "x_train = np.array(x_train).reshape(5*10000, 32*32, 3)\n",
    "\n",
    "# save to disk\n",
    "store(x_train, 'x_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data and save to disk for later usage\n",
    "x_test = []\n",
    "x_test_b = unpickle('cifar-10-batches-py/test_batch').get(bytes('data', 'ascii'))\n",
    "for img in x_test_b:\n",
    "    img = decode_as_image(x_train_b)\n",
    "    x_test.append(img)\n",
    "\n",
    "# reshape the data\n",
    "x_test = np.array(x_test).reshape(1*10000, 32*32, 3)\n",
    "\n",
    "# save to disk\n",
    "store(x_test, 'x_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train labels and save to disk\n",
    "y_train = []\n",
    "for i in range(1, 6):\n",
    "    y_train_b = unpickle('cifar-10-batches-py/data_batch_' + str(i)).get(bytes('labels', 'ascii'))\n",
    "    for img in y_train_b:\n",
    "        y_train.append(img)\n",
    "        \n",
    "# reshape the data\n",
    "y_train = np.array(y_train).flatten()\n",
    "\n",
    "# save to disk\n",
    "store(y_train, 'y_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test labels and save to disk\n",
    "y_test = []\n",
    "y_test_b = unpickle('cifar-10-batches-py/test_batch').get(bytes('labels', 'ascii'))\n",
    "for img in y_test_b:\n",
    "    y_test.append(img)\n",
    "        \n",
    "# reshape the data\n",
    "y_test = np.array(y_test).flatten()\n",
    "\n",
    "# save to disk\n",
    "store(y_test, 'y_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = unpickle(\"cifar-10-batches-py/x_train\")\n",
    "x_test = unpickle(\"cifar-10-batches-py/x_test\")\n",
    "y_train = unpickle(\"cifar-10-batches-py/y_train\")\n",
    "y_test = unpickle(\"cifar-10-batches-py/y_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping from label number to label\n",
    "label_mapping = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "\n",
    "def get_label(i):\n",
    "    return label_mapping[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots the first 3 entries in the train set\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rand = np.random.randint(50000 - 1)\n",
    "i = 0\n",
    "for idx in range(rand, rand + 3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.title(\"Class: {}\".format(get_label(int(y_train[idx]))))\n",
    "    plt.imshow(x_train[idx].reshape(32,32,3))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 32, 32, 3)\n",
    "x_test = x_test.reshape(-1, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: normalize data and cast to float32\n",
    "x_train, x_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define network parameters\n",
    "n_input =  # image shape\n",
    "n_channels =  # number of channels\n",
    "n_classes =  # number of CIFAR-10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding of labels\n",
    "def one_hot_encode(a, length):\n",
    "    temp = np.zeros((a.shape[0], length))\n",
    "    temp[np.arange(a.shape[0]), a] = 1\n",
    "    return temp\n",
    "\n",
    "y_train = one_hot_encode(y_train, n_classes)\n",
    "y_test = one_hot_encode(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define hyper parameters\n",
    "learning_rate =\n",
    "training_iters = \n",
    "batch_size = \n",
    "display_step = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x):\n",
    "    # TODO: define MLP\n",
    "\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[...], outputs=[...])\n",
    "    return model\n",
    "\n",
    "def cnn(x):\n",
    "    # TODO: define CNN\n",
    "\n",
    "    model = tf.keras.Model(inputs=[...], outputs=[...])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build network\n",
    "pred = mlp(x)\n",
    "#pred = cnn(input)\n",
    "\n",
    "# define cost function and optimizer\n",
    "cost = \n",
    "optimizer = \n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=cost,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard configuration\n",
    "logdir = \"./logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "os.makedirs(logdir, exist_ok=True)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
